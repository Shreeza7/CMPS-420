{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNassvKlIphf35saWZVTs5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreeza7/CMPS-420/blob/main/llama3_2blog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "k3C9pnWWLnjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kd-zH4NKLuQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUZmftQHLj3S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the pipeline and model\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Predefined messages with updated system message\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a blog writer who provides blog suggestions and writes blog posts.\"},\n",
        "]\n",
        "\n",
        "# Save the pipeline to be used in other cells\n",
        "%store pipe\n",
        "%store messages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the preloaded pipeline and messages\n",
        "%store -r pipe\n",
        "%store -r messages\n",
        "\n",
        "# Get user input\n",
        "user_input = input(\"Enter your message: \")\n",
        "messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "# Generate the response with optimized settings\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=400,  # Reduce max_new_tokens for faster execution\n",
        ")\n",
        "\n",
        "# Extract and print the generated text without the role structure\n",
        "generated_text = outputs[0][\"generated_text\"]\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "CvJIfJ7vOzUC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}